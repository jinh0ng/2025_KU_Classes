{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcGgHs2tPwnX"
      },
      "source": [
        "### Implementing a Convolutional Neural Network\n",
        "In this exercise, we will develop a convolutional neural network to perform classification, and test it out on cifar-10 dataset. ðŸ˜€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NAL_RKH5Pv7a"
      },
      "outputs": [],
      "source": [
        "# A bit of a set-up\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_JQoiu7yPj9e"
      },
      "outputs": [],
      "source": [
        "# Image Preprocessing\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G49tsijMQquf",
        "outputId": "2648d8c7-01d5-485d-c5ab-5e3190f6befa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:01<00:00, 94577303.06it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10 Dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
        "                                             train=True,\n",
        "                                             transform=transform_train,\n",
        "                                             download=True) # Change Download-flag \"True\" at the first excution.\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
        "                                            train=False,\n",
        "                                            transform=transform_test)\n",
        "\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=100,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNO65w0uTVRQ"
      },
      "source": [
        "### Training VGG Model\n",
        "Here, we have already filled out the `VGG Networks` for you.\n",
        "Practice training the model with this network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yhr7GcUATPKg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, features):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "         # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def vgg16():\n",
        "    # cfg shows 'kernel size'\n",
        "    # 'M' means 'max pooling'\n",
        "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "    return VGG(make_layers(cfg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUZbhBp8WEpn"
      },
      "source": [
        "Here's the training part. It should take a while for training.(30 mins-1 hour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X919NTOMTpwM",
        "outputId": "c6dc4a73-ec46-4f51-fb4c-a5af0b60a319"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-40a198e40200>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [100/500] Loss: 0.1886\n",
            "Epoch [1/1], Step [200/500] Loss: 0.1740\n",
            "Epoch [1/1], Step [300/500] Loss: 0.1789\n",
            "Epoch [1/1], Step [400/500] Loss: 0.1842\n",
            "Epoch [1/1], Step [500/500] Loss: 0.1881\n",
            "Accuracy of the model on the test images: 85.95 %\n"
          ]
        }
      ],
      "source": [
        "model = vgg16().to(device)\n",
        "PATH = './vgg16_epoch250.ckpt'\n",
        "\n",
        "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 1 \n",
        "learning_rate = 0.001\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# For updating learning rate\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "current_lr = learning_rate\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_index, (images, labels) in enumerate(train_loader):\n",
        "        # print(images.shape)\n",
        "        images = images.to(device)  # \"images\" = \"inputs\"\n",
        "        labels = labels.to(device)  # \"labels\" = \"targets\"\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if (batch_index + 1) % 100 == 0:\n",
        "            print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                  .format(epoch + 1, num_epochs, batch_index + 1, total_step, train_loss / (batch_index + 1)))\n",
        "\n",
        "    # Decay learning rate\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        current_lr /= 3\n",
        "        update_lr(optimizer, current_lr)\n",
        "        torch.save(model.state_dict(), './vgg16_epoch' + str(epoch+1)+'.ckpt')\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), './vgg16_final.ckpt')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD5VbNYcTxmz"
      },
      "source": [
        "You must get about 85% accuracy for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd8gnC0Uig4D"
      },
      "source": [
        "### Training Resnet-50 Model\n",
        "Here, we will implement Resnet-50 Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ixTtgBXDjad5"
      },
      "outputs": [],
      "source": [
        "# 1x1 convolution\n",
        "def conv1x1(in_channels, out_channels, stride, padding):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# 3x3 convolution\n",
        "def conv3x3(in_channels, out_channels, stride, padding):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ehngaZUsj876"
      },
      "outputs": [],
      "source": [
        "###########################################################################\n",
        "# Question 1 : Implement the \"bottle neck building block\" part.\n",
        "# Hint : Think about difference between downsample True and False. How we make the difference by code?\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels, downsample=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.downsample = downsample\n",
        "\n",
        "        if self.downsample:\n",
        "            self.layer = nn.Sequential(\n",
        "                ##########################################\n",
        "                ############## fill in here\n",
        "                # Hint : use these functions (conv1x1, conv3x3)\n",
        "                #########################################\n",
        "            )\n",
        "            self.downsize = conv1x1(in_channels, out_channels, 2, 0)\n",
        "\n",
        "        else:\n",
        "            self.layer = nn.Sequential(\n",
        "                ##########################################\n",
        "                ############# fill in here\n",
        "                #########################################\n",
        "            )\n",
        "            self.make_equal_channel = conv1x1(in_channels, out_channels, 1, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample:\n",
        "            out = self.layer(x)\n",
        "            x = self.downsize(x)\n",
        "            return out + x\n",
        "        else:\n",
        "            out = self.layer(x)\n",
        "            if x.size() is not out.size():\n",
        "                x = self.make_equal_channel(x)\n",
        "            return out + x\n",
        "###########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cMchupF7kBZy"
      },
      "outputs": [],
      "source": [
        "###########################################################################\n",
        "# Question 2 : Implement the \"class, ResNet50_layer4\" part.\n",
        "# Understand ResNet architecture and fill in the blanks below.\n",
        "# Implement the code.\n",
        "class ResNet50_layer4(nn.Module):\n",
        "    def __init__(self, num_classes= #blank# ): # Hint : How many classes in Cifar-10 dataset?\n",
        "        super(ResNet50_layer4, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(#blank#, #blank#, #blank#, #blank#, #blank# ),\n",
        "                # Hint : Through this conv-layer, the input image size is halved.\n",
        "                #        Consider stride, kernel size, padding and input & output channel sizes.\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(#blank#, #blank#, #blank#)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            ResidualBlock(#blank#, #blank#, #blank#, #blank#),\n",
        "            ResidualBlock(#blank#, #blank#, #blank#, #blank#),\n",
        "            ResidualBlock(#blank#, #blank#,#blank#, #blank#)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            ##########################################\n",
        "            ############# fill in here \n",
        "            ####### you can refer to the 'layer2' above\n",
        "            #########################################\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            ##########################################\n",
        "            ############# fill in here \n",
        "            ####### you can refer to the 'layer2' above\n",
        "            #########################################\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(#blank#, #blank#) # Hint : Think about the reason why fc layer is needed\n",
        "        self.avgpool = nn.AvgPool2d(#blank#, #blank#)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight.data)\n",
        "            elif isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "###########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USm9xs6rkLkQ"
      },
      "source": [
        "Now, let's train the model. It should take a while for training. (20-30mins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvTFZCZXkN8V",
        "outputId": "59bcc11e-15af-4681-a153-d9d989ee0a12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-f3c225af3b6b>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [100/500] Loss: 0.3698\n",
            "Epoch [1/1], Step [200/500] Loss: 0.3873\n",
            "Epoch [1/1], Step [300/500] Loss: 0.3832\n",
            "Epoch [1/1], Step [400/500] Loss: 0.3723\n",
            "Epoch [1/1], Step [500/500] Loss: 0.3678\n",
            "Accuracy of the model on the test images: 82.1 %\n"
          ]
        }
      ],
      "source": [
        "model = ResNet50_layer4().to(device)\n",
        "PATH = './resnet50_epoch285.ckpt' # test acc would be almost 80\n",
        "\n",
        "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# For updating learning rate\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "current_lr = learning_rate\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_index, (images, labels) in enumerate(train_loader):\n",
        "        # print(images.shape)\n",
        "        images = images.to(device)  # \"images\" = \"inputs\"\n",
        "        labels = labels.to(device)  # \"labels\" = \"targets\"\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if (batch_index + 1) % 100 == 0:\n",
        "            print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                  .format(epoch + 1, num_epochs, batch_index + 1, total_step, train_loss / (batch_index + 1)))\n",
        "\n",
        "    # Decay learning rate\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        current_lr /= 3\n",
        "        update_lr(optimizer, current_lr)\n",
        "        torch.save(model.state_dict(), './resnet50_epoch' + str(epoch+1)+'.ckpt')\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), './resnet50_final.ckpt')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGuEuMpGton5"
      },
      "source": [
        "You must get about 80% accuracy for testing."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
